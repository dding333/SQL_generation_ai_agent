import os
import openai
import glob
import shutil

openai.api_key = os.getenv("OPENAI_API_KEY")

import numpy as np
import pandas as pd

import json
import io
import inspect
import requests
import re

from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
import base64
import email
from email import policy
from email.parser import BytesParser
from email.mime.text import MIMEText

from bs4 import BeautifulSoup
import dateutil.parser as parser

import sys

sys.path.insert(0, './functions/untested functions')
sys.path.insert(0, './functions/tested functions')


def extract_sql(json_str):
    """
    Function to extract an SQL query from a JSON string.
    :param json_str: Input JSON string.
    :return: SQL query string or None if not found.
    """
    data = json.loads(json_str)
    return data.get('sql_query', None)


def check_code_run(messages, functions_list=None, model="gpt-4-0613", function_call="auto", auto_run=True):
    """
    This function interacts with the Chat model to automatically execute external functions if present.
    It can optionally perform the code execution automatically based on the 'auto_run' parameter.

    :param messages: Dictionary representing input messages for the Chat model.
    :param functions_list: Optional list of external functions. Default is None.
    :param model: Model to be used, default is "gpt-4-0613".
    :param function_call: Controls whether external functions are automatically invoked.
    :param auto_run: If True, the function executes code automatically when needed.
    :return: Response generated by the Chat model.
    """

    if functions_list is None:
        response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
        )
        return response["choices"][0]["message"]["content"]

    print("Executing external function to handle the task")

    functions = auto_functions(functions_list)
    available_functions = {func.__name__: func for func in functions_list}

    # First call to the model
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        functions=functions,
        function_call=function_call
    )
    response_message = response["choices"][0]["message"]

    if response_message.get("function_call"):
        function_name = response_message["function_call"]["name"]
        function_to_call = available_functions[function_name]
        function_args = json.loads(response_message["function_call"]["arguments"])

        if not auto_run:
            sql_query = extract_sql(response_message["function_call"]["arguments"])
            confirmation = input(
                f'About to run the following query: {sql_query}. Confirm by entering 1, or cancel with 2: ')
            if confirmation == '2':
                print("Execution canceled.")
                return None
            print("Running code...")

        function_response = function_to_call(**function_args)

        messages.append(response_message)
        messages.append({
            "role": "function",
            "name": function_name,
            "content": function_response,
        })

        second_response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
        )
        return second_response["choices"][0]["message"]["content"]
    else:
        return response_message["content"]


def auto_functions(functions_list):
    """
    Generates the 'functions' parameter required by the Chat model for external function calls.

    :param functions_list: List of function objects.
    :return: A list of dictionaries with function descriptions.
    """

    def generate_function_descriptions(func_list):
        functions = []

        def chen_ming_algorithm(data):
            """
            Function that applies the Chen Ming algorithm to a given dataset.
            :param data: JSON-formatted dataset as a string.
            :return: Computation result in JSON format.
            """
            df_new = pd.read_json(data)
            result = np.sum(df_new, axis=1) - 1
            return result.to_json(orient='records')

        chen_ming_function_desc = inspect.getdoc(chen_ming_algorithm)
        chen_ming_function_name = chen_ming_algorithm.__name__

        chen_ming_function = {
            "name": "chen_ming_algorithm",
            "description": "Executes the Chen Ming algorithm on a dataset.",
            "parameters": {
                "type": "object",
                "properties": {
                    "data": {
                        "type": "string",
                        "description": "Dataset on which to apply the Chen Ming algorithm."
                    }
                },
                "required": ["data"]
            }
        }

        for function in func_list:
            function_desc = inspect.getdoc(function)
            function_name = function.__name__

            user_msg1 = (
                f"Here is a function description: {chen_ming_function_desc}. "
                f"Based on this, create a similar function object. The object should have: "
                f"1. Key 'name' with value '{chen_ming_function_name}'; "
                f"2. Key 'description' with the function's description; "
                f"3. Key 'parameters' describing the input schema."
            )

            assistant_msg1 = json.dumps(chen_ming_function)

            user_prompt = (
                f"Now, based on this example, create a function object for the function '{function_name}' with description: {function_desc}."
            )

            response = openai.ChatCompletion.create(
                model="gpt-4-0613",
                messages=[
                    {"role": "user", "name": "example_user", "content": user_msg1},
                    {"role": "assistant", "name": "example_assistant", "content": assistant_msg1},
                    {"role": "user", "name": "example_user", "content": user_prompt}
                ]
            )
            functions.append(json.loads(response.choices[0].message['content']))
        return functions

    attempts = 0
    max_attempts = 3

    while attempts < max_attempts:
        try:
            return generate_function_descriptions(functions_list)
        except Exception as e:
            attempts += 1
            print(f"Error encountered: {e}")
            print("Pausing due to rate limit. Retrying in 1 minute.")
            if attempts == max_attempts:
                raise
            print("Retrying...")


def run_conversation(messages, functions_list=None, model="gpt-4-0613", function_call="auto"):
    """
    Runs a conversation with the Chat model, optionally including external function calls.

    :param messages: Input messages for the model.
    :param functions_list: List of external functions, optional.
    :param model: The model to be used, default is "gpt-4-0613".
    :param function_call: Controls function call behavior.
    :return: Final response from the model.
    """

    if functions_list is None:
        response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
        )
        return response["choices"][0]["message"]["content"]

    functions = auto_functions(functions_list)
    available_functions = {func.__name__: func for func in functions_list}

    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        functions=functions,
        function_call=function_call
    )
    response_message = response["choices"][0]["message"]

    if response_message.get("function_call"):
        function_name = response_message["function_call"]["name"]
        function_to_call = available_functions[function_name]
        function_args = json.loads(response_message["function_call"]["arguments"])

        function_response = function_to_call(**function_args)

        messages.append(response_message)
        messages.append({
            "role": "function",
            "name": function_name,
            "content": function_response,
        })

        second_response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
        )
        return second_response["choices"][0]["message"]["content"]

    return response_message["content"]


def chat_with_model(functions_list=None, prompt="Hello there", model="gpt-4-0613",
                    system_message=[{"role": "system", "content": "You are a helpful assistant."}]):
    """
    Function to manage user interaction with the Chat model.

    :param functions_list: Optional list of functions available for calling.
    :param prompt: Initial user prompt, default is 'Hello there'.
    :param model: Model to be used, default is 'gpt-4-0613'.
    :param system_message: Initial system message, default is assistant-related.
    """
    messages = system_message
    messages.append({"role": "user", "content": prompt})

    while True:
        response = run_conversation(messages=messages, functions_list=functions_list, model=model)
        print(f"Model Response: {response}")

        user_input = input("Do you have any other questions? (Type 'exit' to end): ")
        if user_input.lower() == "exit":
            del messages
            break
        messages.append({"role": "user", "content": user_input})


def extract_function_code(s, detail=0, tested=False, g=globals()):
    """
    Extract and run Python code from a string. Save the function to the appropriate folder based on whether it's tested or untested.

    :param s: The string containing the function code.
    :param detail: Detail level for displaying the function, 0 or 1.
    :param tested: Indicates whether the function is tested.
    :param g: The globals() for code execution.
    :return: The name of the function extracted.
    """

    def extract_code(s):
        if '```python' in s:
            code_start = s.find('def')
            code_end = s.find('```\n', code_start)
            return s[code_start:code_end]
        return s

    code = extract_code(s)
    match = re.search(r'def (\w+)', code)
    function_name = match.group(1)

    directory = f'./functions/untested functions/{function_name}'
    if not os.path.exists(directory):
        os.makedirs(directory)

    if not tested:
        with open(f'./functions/untested functions/{function_name}/{function_name}_module.py', 'w',
                  encoding='utf-8') as f:
            f.write(code)
    else:
        remove_to_tested(function_name)
        with open(f'./functions/tested functions/{function_name}/{function_name}_module.py', 'w',
                  encoding='utf-8') as f:
            f.write(code)

    try:
        exec(code, g)
    except Exception as e:
        print(f"Error while executing the code: {e}")

    if detail == 0:
        print(f"Extracted function: {function_name}")
    if detail == 1:
        print(open(
            f'./functions/{"tested" if tested else "untested"} functions/{function_name}/{function_name}_module.py').read())

    return function_name


def remove_to_tested(function_name):
    """
    Move a function from the untested to the tested folder and append its code to gptLearning.py.
    """
    with open(f'./functions/untested functions/{function_name}/{function_name}_module.py', encoding='utf-8') as f:
        function_code = f.read()

    with open('gptLearning.py', 'a', encoding='utf-8') as f:
        f.write("\n" + function_code)

    src_dir = f'./functions/untested functions/{function_name}'
    dst_dir = f'./functions/tested functions/{function_name}'

    shutil.move(src_dir, dst_dir)


def show_functions(tested=False, if_print=False):
    """
    Display all functions in the 'tested' or 'untested' folder.

    :param tested: Boolean, whether to display tested functions or untested ones.
    :param if_print: Boolean, whether to print the function names.
    :return: List of function names.
    """
    current_directory = os.getcwd()
    directory = f"{current_directory}\\functions\\{'tested' if tested else 'untested'} functions"

    items = [name for name in os.listdir(directory) if (os.path.splitext(name)[1] == '.py' or os.path.isdir(
        os.path.join(directory, name))) and name != "__pycache__"]

    if if_print:
        for name in items:
            print(name)

    return items


def code_generate(req, few_shot='all', model='gpt-4-0613', g=globals(), detail=0):
    """
    Automatically generate a function based on user requirements and a few-shot prompt strategy.

    :param req: String containing the user request.
    :param few_shot: 'all' by default or a list of specific functions.
    :param model: Model to be used, default is 'gpt-4-0613'.
    :param g: Scope for code execution, default is globals().
    :param detail: Detail level for function extraction, 0 or 1.
    :return: Name of the generated function.
    """
    few_shot_functions_name = show_functions(tested=True) if few_shot == 'all' else few_shot

    with open('./functions/tested functions/system_messages.json', 'r') as f:
        system_messages = json.load(f)

    few_shot_messages = system_messages["system_message"]
    few_shot_messages_CM = system_messages["system_message_CM"]
    few_shot_messages_CD = system_messages["system_message_CD"]

    for function_name in few_shot_functions_name:
        with open(f'./functions/tested functions/{function_name}/{function_name}_prompt.json', 'r') as f:
            msg = json.load(f)
        few_shot_messages_CD.extend(msg["stage1_CD"])
        few_shot_messages_CM.extend(msg["stage1_CM"])
        few_shot_messages.extend(msg["stage2"])

    few_shot_messages_CD.append({"role": "user", "content": req})

    response = openai.ChatCompletion.create(
        model=model,
        messages=few_shot_messages_CD
    )
    new_req_pi = response.choices[0].message['content']

    few_shot_messages_CM.append({"role": "user", "content": req + new_req_pi})
    response = openai.ChatCompletion.create(
        model=model,
        messages=few_shot_messages_CM
    )
    new_req_description = response.choices[0].message['content']

    few_shot_messages.append({"role": "user", "content": new_req_description})
    response = openai.ChatCompletion.create(
        model=model,
        messages=few_shot_messages
    )
    new_req_function = response.choices[0].message['content']

    function_name = extract_function_code(new_req_function, detail=detail, g=g)

    new_req_messages_CD = [{"role": "user", "content": req}, {"role": "assistant", "content": new_req_pi}]
    new_req_messages_CM = [{"role": "user", "content": req + new_req_pi},
                           {"role": "assistant", "content": new_req_description}]
    new_req_messages = [{"role": "user", "content": new_req_description},
                        {"role": "assistant", "content": new_req_function}]

    new_req_prompt = {"stage1_CD": new_req_messages_CD, "stage1_CM": new_req_messages_CM, "stage2": new_req_messages}

    with open(f'./functions/untested functions/{function_name}/{function_name}_prompt.json', 'w') as f:
        json.dump(new_req_prompt, f)

    return function_name


def prompt_modified(function_name, system_content='inference_chain_modification.md', model="gpt-4-0613", g=globals()):
    """
    External function review function for the Intelligent Email project, used to review whether the external function creation prompts are correct and whether the final created code is accurate.
    :param function_name: Required parameter, a string representing the name of the function to be reviewed.
    :param system_content: Optional parameter, default is 'inference_chain_modification.md', representing the name of the document to review the external function's attached document, which should be in Markdown format.
    :param model: Optional parameter, specifies the Chat model to use, default is 'gpt-4-0613'.
    :param g: Optional parameter, specifies the scope for the extract_function_code function, default is globals(), i.e., effective in the current operational space.
    :return: The name of the newly created function after review.
    """
    print(f"Executing review function, review target: {function_name}")
    
    with open(system_content, 'r', encoding='utf-8') as f:
        md_content = f.read()
        
    # Read all prompt content for the original function
    with open(f'./functions/untested functions/{function_name}/{function_name}_prompt.json', 'r') as f:
        msg = json.load(f)
    
    # Save it as a string
    msg_str = json.dumps(msg)
    
    # Perform review
    response = openai.ChatCompletion.create(
                    model=model,
                    messages=[
                    {"role": "system", "content": md_content},
                    {"role": "user", "content": f'The following is an incorrect inference chain for the Intelligent Email project. Please modify it according to the requirements: {msg_str}'}
                    ]
                )
    
    modified_result = response.choices[0].message['content']
    
    def extract_json(s):
        pattern = r'```[jJ][sS][oO][nN]\s*({.*?})\s*```'
        match = re.search(pattern, s, re.DOTALL)
        if match:
            return match.group(1)
        else:
            return s
    
    modified_json = extract_json(modified_result)
    
    # Extract function source code
    code = json.loads(modified_json)['stage2'][1]['content']
    
    # Extract function name
    match = re.search(r'def (\w+)', code)
    function_name = match.group(1)
    
    print(f"Review completed. The new function name is: {function_name}.\nRunning the function definition process and saving function source code and prompt.")
    
    exec(code, g)
    
    # Create a folder with the function's name in the untested folder
    directory = f'./functions/untested functions/{function_name}'
    if not os.path.exists(directory):
        os.makedirs(directory)
        
    # Write the function code
    with open(f'./functions/untested functions/{function_name}/{function_name}_module.py', 'w', encoding='utf-8') as f:
        f.write(code)
        
    # Write the prompt
    with open(f'./functions/untested functions/{function_name}/{function_name}_prompt.json', 'w') as f:
        json.dump(json.loads(modified_json), f)
    
    print(f'New function prompt example saved in ./functions/untested functions/{function_name}/{function_name}_prompt.json')
    print(f"{function_name} function has been defined in the current operational space and can be tested for effectiveness.")
    
    return function_name


def function_test(function_name, req, few_shot, model="gpt-4-0613", g=globals()):

    def test_messages(user_content):
        messages = [
            {"role": "system", "content": "Endumi Tian's email address is: 2323365771@qq.com"},
            {"role": "system", "content": "My email address is: ksken166@gmail.com"},
            {"role": "user", "content": user_content}
        ]
        return messages

    messages = test_messages(req)
    
    new_function = globals()[function_name]
    functions_list = [new_function]
    
    print(f"Testing the functionality of the {function_name} function based on the given user requirement 'req'. Please ensure the function is already defined in the current operational space...")
    
    # This block may raise an error during run_conversation
    # If no error occurs, then run:
    try:
        final_response = run_conversation(messages=messages, functions_list=functions_list, model=model)
        print(f"Current function output: '{final_response}'")
        
        feedback = input("Does the function meet the requirements (yes/no)? ")
        if feedback.lower() == 'yes':
            print("Function has passed the test. Writing the function to the tested folder.")
            remove_to_tested(function_name)
            print('done')
        else:
            next_step = input("The function did not pass the test. Do you want to: 1. Test again, or 2. Enter debug mode?")
            if next_step == '1':
                print("Preparing for retest...")
                function_test(function_name, req, few_shot)
            else:
                solution = input("Choose a debug solution:\n1. Retry the function creation process and test results;\n2. Execute the review function;\n3. Re-enter user requirements;\n4. Exit the program and try manually")
                if solution == '1':
                    # Retry function creation process
                    print("Okay, attempting to recreate the function. Please wait...")
                    few_shot_str = input("For the retest, would you like to: 1. Use the previous Few-shot method, or 2. Use all function examples for Few-shot?")
                    if few_shot_str == '1':
                        function_name = code_generate(req=req, few_shot=few_shot, model=model, g=g)
                    else:
                        function_name = code_generate(req=req, few_shot='all', model=model, g=g)
                    function_test(function_name=function_name, req=req, few_shot=few_shot, g=g)
                elif solution == '2':
                    # Execute the review function
                    print("Okay, executing the review function. Please wait...")
                    function_name = prompt_modified(function_name=function_name, model="gpt-3.5-turbo-16k-0613", g=g)
                    # Proceed to test with the new function
                    print("New function has been created. Proceeding to test...")
                    function_test(function_name=function_name, req=req, few_shot=few_shot, g=g)
                elif solution == '3':
                    new_req = input("Okay, please re-enter the user requirements. Note that the description method will greatly affect the final function creation result.")
                    few_shot_str = input("How would you like to proceed with code generation? 1. Use the previous Few-shot method; \n2. Use all external functions for Few-shot")
                    if few_shot_str == '1':
                        function_name = code_generate(req=new_req, few_shot=few_shot, model=model, g=g)
                    else:
                        function_name = code_generate(req=new_req, few_shot='all', model=model, g=g)
                    function_test(function_name=function_name, req=new_req, few_shot=few_shot, g=g)
                elif solution == '4':
                    print("Okay, good luck with debugging~")
        
    # If run_conversation raises an error, then run:
    except Exception as e:
        next_step = input("run_conversation failed. Would you like to: 1. Retry run_conversation, or 2. Enter debug mode?")
        if next_step == '1':
            function_test(function_name, req, few_shot)
        else:
            solution = input("Choose a debug solution:\n1. Retry the function creation process and test results;\n2. Execute the review function;\n3. Re-enter user requirements;\n4. Exit the program and try manually")
            if solution == '1':
                # Retry function creation process
                print("Okay, attempting to recreate the function. Please wait...")
                few_shot_str = input("For the retest, would you like to: 1. Use the previous Few-shot method, or 2. Use all function examples for Few-shot?")
                if few_shot_str == '1':
                    function_name = code_generate(req=req, few_shot=few_shot, model=model, g=g)
                else:
                    function_name = code_generate(req=req, few_shot='all', model=model, g=g)
                function_test(function_name=function_name, req=req, few_shot=few_shot, g=g)
            elif solution == '2':
                # Execute the review function
                print("Okay, executing the review function. Please wait...")
                max_attempts = 3
                attempts = 0

                while attempts < max_attempts:
                    try:
                        function_name = prompt_modified(function_name=function_name, model="gpt-3.5-turbo-16k-0613", g=g)
                        break  # Break loop if code executes successfully
                    except Exception as e:
                        attempts += 1  # Increase attempt count
                        print("An error occurred:", e)
                        if attempts == max_attempts:
                            print("Maximum attempt count reached. Program terminated.")
                            raise  # Re-raise the last exception
                        else:
                            print("Retrying the review process...")
                # Proceed to test with the new function
                print("New function has been created. Proceeding to test...")
                function_test(function_name=function_name, req=req, few_shot=few_shot, g=g)
            elif solution == '3':
                new_req = input("Okay, please re-enter the user requirements. Note that the description method will greatly affect the final function creation result.")
                few_shot_str = input("How would you like to proceed with code generation? 1. Use the previous Few-shot method; \n2. Use all external functions for Few-shot")
                if few_shot_str == '1':
                    function_name = code_generate(req=new_req, few_shot=few_shot, model=model, g=g)
                else:
                    function_name = code_generate(req=new_req, few_shot='all', model=model, g=g)
                function_test(function_name=function_name, req=new_req, few_shot=few_shot, g=g)
            elif solution == '4':
                print("Okay, good luck with debugging~")

                



if __name__ == '__main__':
    print("this file contains assist functions")
